# KNN-and-SVM-Natural-Language-Processing-Tweet-Stats

This project utilizes several machine learning libraries to get natural text data from twitter and use them to populate a database for classification utlizing KNN and SVM classification algorithms. The purpose for this project is for study of classification techniques, data analysis, and the Python programming language

# Libraries used

The Python libraries used are as follows.

TextBlob
---

This library provides APIs for natural language processing that faciclitate processes like sentiment analysis, tokenization, translation, etc.

For more information and API documentation visit https://textblob.readthedocs.io/en/dev/

Pandas
---

Pandas provides a means for data analysis and for this project it is used for data normalization and data plotting

More info and API documentation at http://pandas.pydata.org/

Scikit-learn
---

This library is where the classification algorithms originate and are used for this project.
It is also used to train and test input data using its train test split method found in its
model selection module.

More info and API documentation at http://scikit-learn.org/stable/

Numpy
---

Used to create a dataframe and manipulate that data frame in order for Scikit-Learn's train-test split of data inputs.

More information and API documentation at http://www.numpy.org/

# Credits

Primary Author: Bryan Campos

Senior Project Mentor: Dr. Yuchou Chang

# License

GNU General Public License v3.0
